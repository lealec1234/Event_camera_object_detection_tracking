{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lealec1234/Event_camera_object_detection_tracking/blob/main/Graph_spectral_clustering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAbTWvoOPeOP",
        "outputId": "d7f7aed7-ed9b-4f8b-cdc8-588920a4fc02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Spectral clustering"
      ],
      "metadata": {
        "id": "RqmEe0nTL87k"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hb-LhB25bs_",
        "outputId": "8b3cfd7a-b00e-4a0b-dad0-46dcaddd5c55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  sample_data\n"
          ]
        }
      ],
      "source": [
        "!dir #check current directory make sure to be in the dataset directory"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file = dtable.fread('/content/drive/MyDrive/honours project/Event_Camera/dataset_dir/DAVIS 240C Dataset/events.txt', sep = ' ').to_pandas()\n",
        "file.columns = ['timestamp', 'x', 'y', 'polarity']\n",
        "file['polarity'] *= 1\n",
        "ts = np.array(file['timestamp'].values)\n",
        "x = np.array(file['x'].values)\n",
        "y = np.array(file['y'].values)\n",
        "pol = np.array(file['polarity'].values)\n",
        "\n",
        "print(ts.shape)\n",
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeHicLEs3CR7",
        "outputId": "0e4dca1b-28e3-4d49-82be-e6a20280b914"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(23126288,)\n",
            "(23126288,)\n",
            "(23126288,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(ts).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7snEUuP3hFj",
        "outputId": "1ab0e8d5-03e7-4ef4-9be6-93b6965d1213"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(18119595,)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dDdeOsu5P2w",
        "outputId": "020d4123-06a5-4805-f3fd-17425d409f51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reading davis dataset...\n",
            "23126288 events in dataset...\n",
            "dividing the sequence into 1000 segments...\n",
            "each segment has 23126 events, out of which 5781 events will be selected...\n",
            "segment no: 1\n",
            "removing noise...\n",
            "constructing graph...\n",
            "finding optimal number of clusters...\n",
            "clustering...\n",
            "saving files...\n",
            "segment no: 2\n",
            "removing noise...\n",
            "constructing graph...\n",
            "finding optimal number of clusters...\n",
            "clustering...\n",
            "saving files...\n",
            "segment no: 3\n",
            "removing noise...\n",
            "constructing graph...\n",
            "finding optimal number of clusters...\n",
            "clustering...\n",
            "saving files...\n",
            "segment no: 4\n",
            "removing noise...\n",
            "constructing graph...\n",
            "finding optimal number of clusters...\n",
            "clustering...\n",
            "saving files...\n",
            "segment no: 5\n",
            "removing noise...\n",
            "constructing graph...\n",
            "finding optimal number of clusters...\n",
            "clustering...\n",
            "saving files...\n",
            "segment no: 6\n",
            "removing noise...\n",
            "constructing graph...\n",
            "finding optimal number of clusters...\n",
            "clustering...\n",
            "saving files...\n",
            "segment no: 7\n",
            "removing noise...\n",
            "constructing graph...\n",
            "finding optimal number of clusters...\n",
            "clustering...\n",
            "saving files...\n",
            "segment no: 8\n",
            "removing noise...\n",
            "constructing graph...\n",
            "finding optimal number of clusters...\n",
            "clustering...\n",
            "saving files...\n",
            "segment no: 9\n",
            "removing noise...\n",
            "constructing graph...\n",
            "finding optimal number of clusters...\n",
            "clustering...\n",
            "saving files...\n",
            "segment no: 10\n",
            "removing noise...\n",
            "constructing graph...\n",
            "finding optimal number of clusters...\n",
            "clustering...\n",
            "saving files...\n",
            "done\n"
          ]
        }
      ],
      "source": [
        "#function to cluster the event camera datasets\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import h5py\n",
        "import numpy as np\n",
        "import warnings\n",
        "from sklearn.neighbors import kneighbors_graph\n",
        "from sklearn.cluster import SpectralClustering\n",
        "from sklearn.metrics import silhouette_score\n",
        "from sklearn.ensemble import IsolationForest\n",
        "print('reading davis dataset...')\n",
        "\n",
        "#davis parameters\n",
        "file = dtable.fread('/content/drive/MyDrive/TRM/DAVIS 240C Dataset/events.txt', sep = ' ').to_pandas()\n",
        "file.columns = ['timestamp', 'x', 'y', 'polarity']\n",
        "file['polarity'] *= 1\n",
        "ts = np.array(file['timestamp'].values)\n",
        "x = np.array(file['x'].values)\n",
        "y = np.array(file['y'].values)\n",
        "pol = np.array(file['polarity'].values)\n",
        "\n",
        "warnings.filterwarnings('ignore', '.*Graph is not fully connected*')\n",
        "ALL = len(pol)\n",
        "NEIGHBORS = 30\n",
        "print(str(ALL)+' events in dataset...')\n",
        "seg = 1000\n",
        "while seg >= 1000:\n",
        "    print('dividing the sequence into '+str(seg)+' segments...')\n",
        "    X = ALL//seg\n",
        "    print('each segment has '+str(X)+' events, out of which '+str(X//4)+' events will be selected...')\n",
        "    for sl_no in range(0,10):\n",
        "\n",
        "        print('segment no: '+str(sl_no+1))\n",
        "        selected_events = []\n",
        "        for i in range(0,ALL)[sl_no*X:sl_no*X+X]:\n",
        "            selected_events.append([y[i], x[i], ts[i]*0.0001, pol[i]*0])\n",
        "        selected_events = np.asarray(selected_events)\n",
        "\n",
        "        print('removing noise...')\n",
        "        cleaned_events = IsolationForest(random_state=0, n_jobs=-1, contamination=0.05).fit(selected_events)\n",
        "        unwanted_events = cleaned_events.predict(selected_events)\n",
        "        selected_events_cleaned = selected_events[np.where(unwanted_events == 1, True, False)]\n",
        "\n",
        "        print('constructing graph...')\n",
        "        adMat_cleaned = kneighbors_graph(selected_events_cleaned, n_neighbors=NEIGHBORS)\n",
        "\n",
        "        print('finding optimal number of clusters...')\n",
        "        max_score = -20\n",
        "        opt_clusters = 2\n",
        "        for CLUSTERS in range(2, 10):\n",
        "            clustering = SpectralClustering(n_clusters=CLUSTERS, random_state=0,\n",
        "                                            affinity='precomputed_nearest_neighbors',\n",
        "                                            n_neighbors=NEIGHBORS, assign_labels='kmeans',\n",
        "                                            n_jobs=-1).fit_predict(adMat_cleaned)\n",
        "            curr_score = silhouette_score(selected_events_cleaned, clustering)\n",
        "            if curr_score > max_score:\n",
        "                max_score = curr_score\n",
        "                opt_clusters = CLUSTERS\n",
        "\n",
        "        print('clustering...')\n",
        "        clustering_opt = SpectralClustering(n_clusters=opt_clusters, random_state=0,\n",
        "                                            affinity='precomputed_nearest_neighbors',\n",
        "                                            n_neighbors=NEIGHBORS, assign_labels='kmeans',\n",
        "                                            n_jobs=-1).fit_predict(adMat_cleaned)\n",
        "\n",
        "        print('saving files...')\n",
        "\n",
        "        yy = str(sl_no)\n",
        "        file_name = yy\n",
        "        os.makedirs('results/davis240/'+str(seg)+'/selected_events', exist_ok=True)\n",
        "        os.makedirs('results/davis240/'+str(seg)+'/clusters', exist_ok=True)\n",
        "        np.save(os.path.join('results/davis240/'+str(seg)+'/selected_events', file_name + '.npy'), selected_events_cleaned)\n",
        "        np.save(os.path.join('results/davis240/'+str(seg)+'/clusters', file_name + '.npy'), clustering_opt)\n",
        "    break\n",
        "print('done')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "8cwkKKQhLxVe",
        "RqmEe0nTL87k",
        "oh2rvf04NC_7",
        "_PMMpS78M0tj"
      ],
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}